{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL in Python - Connecting to and retrieving data from PostgreSQL\n",
    "\n",
    "Previously, you have learned how to connect to a SQL database by using a SQL client such as DBeaver. Apart from connecting to databases, DBeaver also allows you to run SQL queries against the database, create new tables and populate them with data as well as retrieving the data.\n",
    "\n",
    "Python also allows executing SQL queries and getting the result into a Python object, for example a Pandas data frame. Instead of exporting a .csv file from DBeaver you can directly get the data you need into Python and continue your work. In addition we can reduce the steps by connecting to the database from Python directly, eliminating the need for a separate SQL client.\n",
    "\n",
    "After you have the data in Python in the required shape you can export the data into a .csv file. This file is for your own reference, please avoid sending .csv files around - database is the point of reference when it comes to data. \n",
    "\n",
    "Having a copy of a .csv file (or another format) can speed up your analysis work. Imagine that the query takes 25 minutes to run. If you made some mistakes in your Python code you might need to go back to the original dataset. Instead of having to rerun the SQL query and having to wait you can read in the .csv file you have previously saved on your hard disk into Python and continue with your analysis work. \n",
    "\n",
    "**In this notebook you will see 2 ways to connect to SQL-Databases and export the data to a CSV file**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a connection to a PostgreSQL database with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 python packages that are the \"go-to\" when it comes to connecting to SQL-Databases: `psycopg2` and `sqlalchemy` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting via psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import psycopg2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to create a connection to our PostgreSQL database we need the following information:\n",
    "\n",
    "- host = the address of the machine the database is hosted on\n",
    "- port = the virtual gate number through which communication will be allowed\n",
    "- database = the name of the database\n",
    "- user = the name of the user\n",
    "- password = the password of the user\n",
    "\n",
    "Because we don't want that the database information is published on github we put it into a `.env` file which is added into the `.gitignore`. \n",
    "In these kind of files you can store information that is not supposed to be published.\n",
    "With the `dotenv` package you can read the `.env` files and get the variables.\n",
    "(We will share the file with you on Slack!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # READ database user password host and port from .env\n",
    "# load_dotenv()\n",
    "\n",
    "# DATABASE = os.getenv('DATABASE')\n",
    "# USER_DB = os.getenv('USER_DB')\n",
    "# PASSWORD = os.getenv('PASSWORD')\n",
    "# HOST = os.getenv('HOST')\n",
    "# PORT = os.getenv('PORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function from the psycopg2 package to create a connection is called `connect()`.\n",
    "`connect()` expects the parameters listed above as input in order to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create connection object conn\n",
    "# conn = psycopg2.connect(\n",
    "#     database=DATABASE,\n",
    "#     user=USER_DB,\n",
    "#     password=PASSWORD,\n",
    "#     host=HOST,\n",
    "#     port=PORT\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data from the database with psycopg2\n",
    "\n",
    "Before we can use our connection to get data, we have to create a cursor. A cursor allows Python code to execute PostgreSQL commmands in a database session.\n",
    "A cursor has to be created with the `cursor()` method of our connection object conn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run SQL-Queries with `cur.execute('QUERY')` and then run `cur.fetchall()` to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute('SELECT * FROM eda.king_county_house_sales LIMIT 10')\n",
    "# cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- With `conn.close()` you can close the connection again. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to work with the data. The easiest way is to import the data into pandas dataframes. We can use `pd.read_sql_query` or `pd.read_sql_table` or for convenience `pd.read_sql`.\n",
    "\n",
    "This function is a convenience wrapper around read_sql_table and read_sql_query (for backward compatibility). It will delegate to the specific function depending on the provided input. A SQL query will be routed to read_sql_query , while a database table name will be routed to read_sql_table . Note that the delegated function might have more specific notes about their functionality not listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open connection again because we closed it\n",
    "# conn = psycopg2.connect(\n",
    "#     database=DATABASE,\n",
    "#     user=USER_DB,\n",
    "#     password=PASSWORD,\n",
    "#     host=HOST,\n",
    "#     port=PORT\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the data into a pandas dataframe\n",
    "# query_string = \"SELECT * FROM eda.king_county_house_sales LIMIT 10\"\n",
    "# df_psycopg = pd.read_sql(query_string, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_psycopg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "# df_psycopg.to_csv('data/testeda.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting and retrieving data via SQLAlchemy\n",
    "\n",
    "`sqlalchemy` works similarly. Here you have to create an engine with the database sting (a link that includes every information we entered in the conn object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 읽기\n",
    "DATABASE = os.getenv('DATABASE')\n",
    "USER_DB = os.getenv('USER_DB')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "HOST = os.getenv('HOST')\n",
    "PORT = os.getenv('PORT')\n",
    "\n",
    "# DB 연결 문자열 생성\n",
    "DB_STRING = f\"postgresql://{USER_DB}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\"\n",
    "db = create_engine(DB_STRING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can import that engine with a query into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>house_id</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>grade</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>98178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>98125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>98028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>98136</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>98074</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    house_id  zipcode  bedrooms  bathrooms  floors  sqft_living  \\\n",
       "0   1  7129300520    98178       3.0       1.00     1.0       1180.0   \n",
       "1   2  6414100192    98125       3.0       2.25     2.0       2570.0   \n",
       "2   3  5631500400    98028       2.0       1.00     1.0        770.0   \n",
       "3   4  2487200875    98136       4.0       3.00     1.0       1960.0   \n",
       "4   5  1954400510    98074       3.0       2.00     1.0       1680.0   \n",
       "\n",
       "   sqft_lot  yr_built  grade   sold_date     price  \n",
       "0    5650.0      1955      7  2014-10-13  221900.0  \n",
       "1    7242.0      1951      7  2014-12-09  538000.0  \n",
       "2   10000.0      1933      6  2015-02-25  180000.0  \n",
       "3    5000.0      1965      7  2014-12-09  604000.0  \n",
       "4    8080.0      1987      8  2015-02-18  510000.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  s.id,\n",
    "  d.id AS house_id,\n",
    "  d.zipcode, \n",
    "  d.bedrooms,\n",
    "  d.bathrooms,\n",
    "  d.floors,\n",
    "  d.sqft_living,\n",
    "  d.sqft_lot,\n",
    "  d.yr_built, \n",
    "  d.grade,\n",
    "  s.date AS sold_date,\n",
    "  s.price\n",
    "FROM eda.king_county_house_details AS d\n",
    "LEFT JOIN eda.king_county_house_sales AS s\n",
    "  ON d.id = s.house_id;\n",
    "\"\"\"\n",
    "\n",
    "# 데이터 가져오기\n",
    "df = pd.read_sql(query, db)  # ← db로 수정\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't want to run the queries over and over again we can export the data into a .csv file in order to use it in other notebooks as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df.to_csv('data/eda.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data from a csv-file\n",
    "# 여기서 csv 파일이 만들어짐 \n",
    "df = pd.read_csv('data/eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "86bfcc733a99316639cfae738bd2c12342c3c5e2c4e3f470908e9f9639795c12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
